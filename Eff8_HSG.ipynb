{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1cRA_Nj6a-Yiu_yPR_1nV2aE1xx1yNi2N",
      "authorship_tag": "ABX9TyOkehmzqHS/9/h/yz8pgL0/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sungi-Hwang/Carclassification/blob/main/Eff8_HSG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc, torch, sys\n",
        "import os\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "# 1) ëª¨ë¸Â·í…ì„œÂ·ë°ì´í„° ì§€ìš°ê¸°\n",
        "# del model, xb, yb, logits, loss   # ë‚¨ì•„ ìˆì„ ë³€ìˆ˜ ì „ë¶€!\n",
        "gc.collect()\n",
        "\n",
        "# 2) CUDA ìºì‹œ ë¹„ìš°ê¸° (reserved í•´ì œ)\n",
        "torch.cuda.empty_cache()          # <â”€ ëŒ€ë¶€ë¶„ ì´ê±¸ë¡œ í•´ê²°\n",
        "\n",
        "# 3) í•„ìš”í•˜ë©´ ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™”ê¹Œì§€\n",
        "torch.cuda.ipc_collect()          # (ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ í• ë‹¹í•œ ë©”ëª¨ë¦¬ê¹Œì§€ íšŒìˆ˜)\n",
        "\n",
        "# 4) ë‚¨ì€ ê²Œ ìˆë‚˜ í™•ì¸\n",
        "print(torch.cuda.memory_allocated()/1e9,\n",
        "      torch.cuda.memory_reserved()/1e9, 'GB')\n"
      ],
      "metadata": {
        "id": "qg7auaiPa-g1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4ea1f8-4f18-4eac-c3ae-78d107be36be"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.734860288 6.07125504 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # í•œ ë²ˆë§Œ ì‹¤í–‰\n",
        "# !unzip -oq \"/content/drive/MyDrive/Colab Notebooks/open.zip\" \\\n",
        "#        -d \"/content/drive/MyDrive/Dacon/\"\n"
      ],
      "metadata": {
        "id": "0j2ZFxTS227Q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. IMPORT & ê¸°ë³¸ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import os, random, numpy as np, torch, gc\n",
        "import torch.nn as nn, torch.nn.functional as F\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import transforms\n",
        "from torchvision.models import efficientnet_v2_m, EfficientNet_V2_M_Weights\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageFile; ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32      = True\n",
        "AMP_DTYPE = torch.bfloat16\n",
        "# â— ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ í•œ ê³³ì—\n",
        "CFG = {\n",
        "    \"EPOCHS\"      : 15,\n",
        "    \"BATCH_SIZE\"  : 64,        # OOM ë‚˜ë©´ ë” â†“\n",
        "    \"LR\"          : 1e-4,\n",
        "    \"WEIGHT_DECAY\": 1e-4,\n",
        "}\n",
        "\n",
        "# â— FP16 ì´ ì•„ë‹Œ ê²½ìš°ì—” GradScaler íš¨ë ¥ ì—†ìŒ â†’ ìë™ ë¹„í™œì„±\n",
        "scaler = GradScaler(enabled = (AMP_DTYPE is torch.float16))"
      ],
      "metadata": {
        "id": "1IedKvjnLdaC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "gunh9vkzk4Ep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37cd2792-b503-478f-f363-83b846218955"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. ë¼ë²¨ ì •ê·œí™” ë„ìš°ë¯¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "from collections import defaultdict\n",
        "\n",
        "alias_pairs = [\n",
        "    (\"K5_3ì„¸ëŒ€_í•˜ì´ë¸Œë¦¬ë“œ_2020_2022\", \"K5_í•˜ì´ë¸Œë¦¬ë“œ_3ì„¸ëŒ€_2020_2023\"),\n",
        "    (\"ë””_ì˜¬ë‰´ë‹ˆë¡œ_2022_2025\"      , \"ë””_ì˜¬_ë‰´_ë‹ˆë¡œ_2022_2025\"),\n",
        "    (\"718_ë°•ìŠ¤í„°_2017_2024\"       , \"ë°•ìŠ¤í„°_718_2017_2024\"),\n",
        "]\n",
        "alias = {b: a for a, b in alias_pairs} | {a: a for a, _ in alias_pairs}\n",
        "canon  = lambda lbl: alias.get(lbl, lbl)\n",
        "# ğŸ” ì—­ë§¤í•‘\n",
        "canon_to_originals = defaultdict(list)\n",
        "for a, b in alias_pairs:\n",
        "    canon_to_originals[canon(a)].append(a)\n",
        "    canon_to_originals[canon(b)].append(b)\n"
      ],
      "metadata": {
        "id": "C6Fu6e3pi9BR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.samples = []  # (image_path, canonical_class)\n",
        "        self.original_classes = []  # original label\n",
        "        self.canonical_classes = []  # canonical label\n",
        "\n",
        "        for p in sorted(Path(root).iterdir()):\n",
        "            if p.is_dir():\n",
        "                orig = p.name\n",
        "                cls = canon(orig)\n",
        "                self.original_classes.append(orig)\n",
        "                self.canonical_classes.append(cls)\n",
        "\n",
        "                for img in p.glob(\"*.jpg\"):\n",
        "                    self.samples.append((img, cls))\n",
        "\n",
        "        self.classes = sorted(set(self.canonical_classes))\n",
        "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
        "        self.idx_to_class = {i: c for c, i in self.class_to_idx.items()}\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, cls = self.samples[idx]\n",
        "        img = Image.open(path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, self.class_to_idx[cls]\n"
      ],
      "metadata": {
        "id": "0RJCL3H_BK9a"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. í´ë˜ìŠ¤ ëª©ë¡ & Transform â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "sub = pd.read_csv(\"/content/drive/MyDrive/Dacon/sample_submission.csv\")\n",
        "CLASS_NAMES = [canon(c) for c in sub.columns[1:]]\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "weights  = EfficientNet_V2_M_Weights.DEFAULT\n",
        "preset   = weights.transforms()\n",
        "IMG_SIZE = 480\n",
        "train_tf = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0), antialias=True),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    preset,\n",
        "])\n",
        "val_tf = transforms.Compose([\n",
        "    transforms.Resize(int(IMG_SIZE*1.15), antialias=True),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    preset,\n",
        "])"
      ],
      "metadata": {
        "id": "zdECrE8zZXnX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 5. Dataset & DataLoader â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "root = \"/content/drive/MyDrive/Dacon/train\"\n",
        "ds_full   = CustomImageDataset(root, transform=train_tf)\n",
        "ds_full_v = CustomImageDataset(root, transform=val_tf)\n",
        "\n",
        "targets   = [lbl for _, lbl in ds_full.samples]\n",
        "tr_idx, v_idx = train_test_split(\n",
        "    np.arange(len(ds_full)),\n",
        "    test_size=0.2,\n",
        "    stratify=targets,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    Subset(ds_full, tr_idx),\n",
        "    batch_size = CFG[\"BATCH_SIZE\"],     # â— CFG ì‚¬ìš©\n",
        "    shuffle    = True,\n",
        "    num_workers=8,\n",
        "    pin_memory = True,\n",
        "    persistent_workers=True,\n",
        "    prefetch_factor=4,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    Subset(ds_full_v, v_idx),\n",
        "    batch_size = CFG[\"BATCH_SIZE\"],     # â— CFG ì‚¬ìš©\n",
        "    shuffle    = False,\n",
        "    num_workers=4,\n",
        "    pin_memory = True,\n",
        "    persistent_workers=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "6msh-TKiYieo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 6. ëª¨ë¸, Optim, Criterion â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "model = efficientnet_v2_m(weights=weights)\n",
        "in_f  = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(in_f, NUM_CLASSES)\n",
        "\n",
        "model = model.to(device, dtype=AMP_DTYPE, memory_format=torch.channels_last)  # â—\n",
        "model = model\n",
        "crit = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "opt  = torch.optim.AdamW(\n",
        "          model.parameters(),\n",
        "          lr          = CFG[\"LR\"],          # â—\n",
        "          weight_decay= CFG[\"WEIGHT_DECAY\"],\n",
        "          fused=True\n",
        "      )\n"
      ],
      "metadata": {
        "id": "pVdQDCJBYv3_"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 7. Train / Val ë£¨í”„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "best = np.inf\n",
        "SAVE_PATH = \"/content/drive/MyDrive/best_model.pth\"\n",
        "for ep in range(CFG[\"EPOCHS\"]):\n",
        "    # ---- train ----\n",
        "    model.train(); tl = 0\n",
        "    for xb, yb in tqdm(train_loader, desc=f\"Ep{ep+1} Train\"):\n",
        "        xb = xb.to(device, memory_format=torch.channels_last, dtype = AMP_DTYPE)  # â—\n",
        "        yb = yb.to(device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        # with torch.no_grad():\n",
        "        #     print(\"âœ” yb.shape:\", yb.shape)\n",
        "        #     print(\"âœ” yb.dtype:\", yb.dtype)\n",
        "        #     print(\"âœ” yb min:\", yb.min().item(), \"max:\", yb.max().item())\n",
        "        #     dummy_x = torch.randn_like(xb, dtype=AMP_DTYPE)\n",
        "        #     dummy_out = model(dummy_x)\n",
        "        #     print(\"âœ” logits.shape[1] (num_classes):\", dummy_out.shape[1])\n",
        "        #     assert yb.dtype == torch.long\n",
        "        #     assert yb.max() < dummy_out.shape[1], \"â— yb ê°’ì´ í´ë˜ìŠ¤ ìˆ˜ë³´ë‹¤ í½ë‹ˆë‹¤!\"\n",
        "        with autocast(\"cuda\",dtype=AMP_DTYPE):             # â—\n",
        "            logits = model(xb)\n",
        "            loss   = crit(logits, yb)\n",
        "\n",
        "        if scaler.is_enabled():                             # â— FP16 ì „ìš© ê²½ë¡œ\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "        else:                                               # â— BF16 ê²½ë¡œ\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "        tl += loss.item()\n",
        "\n",
        "    # ---- val ----\n",
        "    model.eval(); all_p, all_y = [], []; correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in tqdm(val_loader, desc=f\"Ep{ep+1} Val\"):\n",
        "            xb = xb.to(device, memory_format=torch.channels_last, dtype=AMP_DTYPE)\n",
        "            yb = yb.to(device)\n",
        "            # with torch.no_grad():\n",
        "            #     print(\"âœ” yb.shape:\", yb.shape)\n",
        "            #     print(\"âœ” yb.dtype:\", yb.dtype)\n",
        "            #     print(\"âœ” yb min:\", yb.min().item(), \"max:\", yb.max().item())\n",
        "            #     print(\"âœ” logits.shape[1] (num_classes):\", model(torch.randn_like(xb)).shape[1])\n",
        "            #     assert yb.dtype == torch.long\n",
        "            #     assert yb.max() < model(torch.randn_like(xb)).shape[1]\n",
        "            with autocast(\"cuda\", dtype=AMP_DTYPE):\n",
        "                out = model(xb)\n",
        "            prob = F.softmax(out, 1)\n",
        "            pred = prob.argmax(1)\n",
        "            correct += (pred == yb).sum().item(); total += yb.size(0)\n",
        "            all_p.append(prob.cpu().float().numpy())\n",
        "            all_y.append(yb.cpu().numpy())\n",
        "\n",
        "    logloss = log_loss(np.concatenate(all_y), np.concatenate(all_p))\n",
        "    acc     = 100 * correct / total\n",
        "    print(f\"Ep{ep+1:02d}  train_loss={tl/len(train_loader):.4f}  \"\n",
        "          f\"val_logloss={logloss:.4f}  acc={acc:.2f}%\")\n",
        "\n",
        "    if logloss < best:\n",
        "        best = logloss\n",
        "        torch.save(model.state_dict(), SAVE_PATH)\n",
        "        print(\"   âœ… best_model.pth saved (improved)\")"
      ],
      "metadata": {
        "id": "cknC4-7WYyj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "270f345a-6749-4e1f-86a8-cb115a5e694f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep1 Train:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 188/415 [01:50<02:09,  1.75it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = next(iter(train_loader))\n",
        "print(\"âœ” yb shape:\", yb.shape)\n",
        "print(\"âœ” yb dtype:\", yb.dtype)\n",
        "print(\"âœ” yb min:\", yb.min().item())\n",
        "print(\"âœ” yb max:\", yb.max().item())\n",
        "\n",
        "# ê·¸ë¦¬ê³ \n",
        "logits = model(xb.to(device))\n",
        "print(\"âœ” logits shape:\", logits.shape)\n"
      ],
      "metadata": {
        "id": "gj1DkBmkeBp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}