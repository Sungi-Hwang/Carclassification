{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11996333,"sourceType":"datasetVersion","datasetId":7545953}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-06-04T05:46:41.643369Z","iopub.execute_input":"2025-06-04T05:46:41.643655Z"}}},{"cell_type":"code","source":"# Swin‑Tiny 기반 차량 분류 파이프라인 (Kaggle)\n# --------------------------------------------------\n# - ConvNeXt‑Tiny, B5 와 앙상블 시 정보 다양성을 극대화하기 위해 Transformer 계열(Swin‑Tiny)을 채택\n# - 30 K 데이터셋에서도 안정적으로 학습할 수 있도록 RandAugment+MixUp/CutMix 를 포함\n# --------------------------------------------------\n\nfrom __future__ import annotations\n\nimport os\nfrom pathlib import Path\nfrom typing import Dict, Any, Tuple, List\n\nimport torch\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Optimizer\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nimport timm\nfrom timm.data import Mixup, RandAugment\nfrom timm.loss import SoftTargetCrossEntropy\nfrom torchvision import transforms\n\n# ──────────────────────────────────────────────────────────────────────────\n# 0. Config & Globals\n# -------------------------------------------------------------------------\n\nCFG: Dict[str, Any] = {\n    \"MODEL\": \"swin_tiny_patch4_window7_224\",  # Swin‑Tiny (patch 4, win 7, 224×224)\n    \"EPOCHS\": 20,\n    \"PATIENCE\": 5,\n    \"T_0\": 10,\n    \"BATCH_SIZE\": 32,            # 16 GB GPU 기준 224² 배치 32 OK ‑ 부족하면 16 으로 ↓\n    \"NUM_WORKERS\": 4,\n    \"IMG_SIZE\": 224,             # 학습 후반(혹은 2nd stage)에 384 로 키우면 +1~2 pp\n    \"VAL_RATIO\": 0.1,\n    \"MIXUP_PROB\": 0.8,\n    \"MIXUP_ALPHA\": 0.2,\n    \"CUTMIX_ALPHA\": 1.0,\n}\n\nDATA_DIR = Path(\"/kaggle/input/car-classfication\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\nSAVE_DIR = Path(\"/kaggle/working\")\nSAVE_DIR.mkdir(parents=True, exist_ok=True)\n\nBEST_MODEL_PATH = SAVE_DIR / \"best_model_swin.pth\"\nCKPT_PATH = SAVE_DIR / \"ckpt_swin.pth\"\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Read class names\nCLASS_NAMES = sorted([p.name for p in TRAIN_DIR.iterdir() if p.is_dir()])\nNUM_CLASSES = len(CLASS_NAMES)\nLABEL_TO_IDX = {label: idx for idx, label in enumerate(CLASS_NAMES)}\n\n# ──────────────────────────────────────────────────────────────────────────\n# 1. Utility: EarlyStopping (accuracy based)\n# -------------------------------------------------------------------------\n\n\nclass EarlyStopping:\n    def __init__(self, patience: int, path: str | os.PathLike):\n        self.patience = patience\n        self.counter = 0\n        self.best_score = -float(\"inf\")\n        self.early_stop = False\n        self.path = Path(path)\n\n    def __call__(self, score: float, model: nn.Module):\n        if score > self.best_score:\n            self.best_score = score\n            self.counter = 0\n            state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n            torch.save(state_dict, self.path)\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 2. Dataset & Transforms\n# -------------------------------------------------------------------------\n\n\ndef pad_to_square(img: Image.Image, fill_color=(0, 0, 0)):\n    w, h = img.size\n    max_side = max(w, h)\n    pad_w = (max_side - w) // 2\n    pad_h = (max_side - h) // 2\n    padding = (pad_w, pad_h, max_side - w - pad_w, max_side - h - pad_h)\n    return transforms.functional.pad(img, padding, fill=fill_color, padding_mode=\"constant\")\n\n\nrand_augment = RandAugment(num_layers=2, magnitude=9)\n\ntrain_tf = transforms.Compose([\n    transforms.Lambda(pad_to_square),\n    transforms.RandomChoice([\n        transforms.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n        transforms.RandomResizedCrop(CFG[\"IMG_SIZE\"], scale=(0.7, 1.0), ratio=(0.9, 1.1)),\n    ]),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    rand_augment,\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    transforms.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=\"random\"),\n])\n\n\nval_tf = transforms.Compose([\n    transforms.Lambda(pad_to_square),\n    transforms.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, samples: List[Tuple[Path, int]], transform=None):\n        self.samples = samples\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx: int):\n        img_path, label = self.samples[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\n\nclass TestDataset(Dataset):\n    def __init__(self, paths: List[Path], transform=None):\n        self.paths = paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx: int):\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 3. Build model / loaders\n# -------------------------------------------------------------------------\n\n\ndef build_model() -> nn.Module:\n    model = timm.create_model(CFG[\"MODEL\"], pretrained=True, num_classes=NUM_CLASSES)\n    return model\n\n\ndef build_loaders() -> Tuple[DataLoader, DataLoader, DataLoader, List[Path]]:\n    train_samples = []\n    for class_dir in TRAIN_DIR.iterdir():\n        if class_dir.is_dir():\n            label = LABEL_TO_IDX[class_dir.name]\n            for img_path in class_dir.glob(\"*.jpg\"):\n                train_samples.append((img_path, label))\n\n    train_imgs, val_imgs = train_test_split(\n        train_samples,\n        test_size=CFG[\"VAL_RATIO\"],\n        stratify=[label for _, label in train_samples],\n        random_state=42,\n    )\n\n    train_ds = CustomDataset(train_imgs, transform=train_tf)\n    val_ds = CustomDataset(val_imgs, transform=val_tf)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=CFG[\"BATCH_SIZE\"],\n        shuffle=True,\n        num_workers=CFG[\"NUM_WORKERS\"],\n        pin_memory=True,\n        persistent_workers=True,\n        drop_last=True,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=CFG[\"BATCH_SIZE\"],\n        shuffle=False,\n        num_workers=CFG[\"NUM_WORKERS\"],\n        pin_memory=True,\n        persistent_workers=True,\n    )\n\n    test_paths = sorted(list(TEST_DIR.glob(\"*.jpg\")))\n    test_ds = TestDataset(test_paths, transform=val_tf)\n    test_loader = DataLoader(\n        test_ds,\n        batch_size=CFG[\"BATCH_SIZE\"],\n        shuffle=False,\n        num_workers=CFG[\"NUM_WORKERS\"],\n        pin_memory=True,\n        persistent_workers=True,\n    )\n\n    return train_loader, val_loader, test_loader, test_paths\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 4. Optimizer & Scheduler\n# -------------------------------------------------------------------------\n\n\ndef build_optim_sched(model: nn.Module) -> Tuple[Optimizer, CosineAnnealingWarmRestarts]:\n    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-2)\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG[\"T_0\"], T_mult=1)\n    return optimizer, scheduler\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 5. Checkpoint\n# -------------------------------------------------------------------------\n\n\ndef load_checkpoint_if_exists(\n    model: nn.Module,\n    optimizer: Optimizer,\n    scaler: GradScaler,\n    scheduler: CosineAnnealingWarmRestarts,\n) -> int:\n    start_epoch = 0\n    if CKPT_PATH.exists():\n        print(f\"✅ Checkpoint found. Loading from {CKPT_PATH}\")\n        ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n        model.load_state_dict(ckpt[\"model_state\"])\n        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n        scaler.load_state_dict(ckpt[\"scaler_state\"])\n        scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n        start_epoch = ckpt[\"epoch\"] + 1\n        print(f\"➡️  Resuming from epoch {start_epoch}\")\n    return start_epoch\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 6. Train & Validate\n# -------------------------------------------------------------------------\n\n\ndef train_one_epoch(model, loader, optimizer, scaler, scheduler, epoch, mixup_fn):\n    model.train()\n    running_loss = 0.0\n    pbar = tqdm(loader, desc=f\"Epoch {epoch}\", ncols=110, leave=False)\n    for step, (xb, yb) in enumerate(pbar):\n        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n\n        # MixUp / CutMix\n        if mixup_fn is not None:\n            xb, yb = mixup_fn(xb, yb)\n\n        with autocast(dtype=torch.float16):\n            preds = model(xb)\n            loss = criterion(preds, yb)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step(epoch + (step + 1) / len(loader))\n\n        running_loss += loss.item()\n        pbar.set_postfix(loss=f\"{running_loss / (step + 1):.4f}\")\n\n    return running_loss / len(loader)\n\n\n@torch.no_grad()\ndef validate(model, loader):\n    model.eval()\n    val_loss, correct, total = 0.0, 0, 0\n    for xb, yb in loader:\n        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n        with autocast(dtype=torch.float16):\n            preds = model(xb)\n            loss = criterion_val(preds, yb)\n        val_loss += loss.item()\n        correct += (preds.argmax(1) == yb).sum().item()\n        total += yb.size(0)\n    return val_loss / len(loader), correct / total\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 7. Main train\n# -------------------------------------------------------------------------\n\n\ndef fit():\n    train_loader, val_loader, test_loader, test_paths = build_loaders()\n\n    model = build_model()\n    if torch.cuda.device_count() > 1:\n        model = nn.DataParallel(model)\n    model.to(DEVICE)\n\n    optimizer, scheduler = build_optim_sched(model)\n    scaler = GradScaler(enabled=DEVICE.type == \"cuda\")\n    start_epoch = load_checkpoint_if_exists(model, optimizer, scaler, scheduler)\n\n    mixup_fn = Mixup(\n        mixup_alpha=CFG[\"MIXUP_ALPHA\"],\n        cutmix_alpha=CFG[\"CUTMIX_ALPHA\"],\n        prob=CFG[\"MIXUP_PROB\"],\n        num_classes=NUM_CLASSES,\n        label_smoothing=0.1,\n    )\n\n    early_stopping = EarlyStopping(patience=CFG[\"PATIENCE\"], path=BEST_MODEL_PATH)\n\n    for epoch in range(start_epoch, CFG[\"EPOCHS\"]):\n        train_loss = train_one_epoch(model, train_loader, optimizer, scaler, scheduler, epoch, mixup_fn)\n        val_loss, val_acc = validate(model, val_loader)\n        print(f\"Epoch {epoch:02d} | Train {train_loss:.4f} | Val {val_loss:.4f} | Acc {val_acc:.4f}\")\n\n        ckpt = {\n            \"epoch\": epoch,\n            \"model_state\": model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n            \"scaler_state\": scaler.state_dict(),\n            \"scheduler_state\": scheduler.state_dict(),\n        }\n        torch.save(ckpt, CKPT_PATH)\n\n        early_stopping(val_acc, model)\n        if early_stopping.early_stop:\n            print(\"\\n🚨 Early stopping triggered\")\n            break\n\n    best_state = torch.load(BEST_MODEL_PATH, map_location=DEVICE)\n    model.load_state_dict(best_state)\n    return model, test_loader, test_paths\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 8. Inference\n# -------------------------------------------------------------------------\n\n\ndef inference(model, test_loader, test_paths):\n    model.eval()\n    all_probs = []\n    with torch.inference_mode():\n        for xb in tqdm(test_loader, desc=\"Test\", ncols=100, leave=False):\n            xb = xb.to(DEVICE, non_blocking=True)\n            with autocast(dtype=torch.float16):\n                preds = model(xb)\n            probs = preds.softmax(dim=1).cpu().numpy()\n            all_probs.append(probs)\n    probs_cat = np.concatenate(all_probs, axis=0)\n    final_preds = probs_cat.argmax(1)\n\n    sub = pd.DataFrame({\n        \"id\": [p.stem for p in test_paths],\n        \"label\": final_preds,\n    })\n    sub.to_csv(SAVE_DIR / \"submission_swin.csv\", index=False, encoding=\"utf-8-sig\")\n    print(f\"✅ submission_swin.csv saved to {SAVE_DIR}\")\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 9. Loss (defined globally to share across funcs)\n# -------------------------------------------------------------------------\n\ncriterion = SoftTargetCrossEntropy()\ncriterion_val = nn.CrossEntropyLoss()\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 10. Entry point\n# -------------------------------------------------------------------------\n\nif __name__ == \"__main__\":\n    model, test_loader, test_paths = fit()\n    inference(model, test_loader, test_paths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:36:38.764402Z","iopub.execute_input":"2025-06-04T06:36:38.764662Z","iopub.status.idle":"2025-06-04T06:36:38.844846Z","shell.execute_reply.started":"2025-06-04T06:36:38.764644Z","shell.execute_reply":"2025-06-04T06:36:38.843828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from __future__ import annotations\n\nimport os\nfrom pathlib import Path\nfrom typing import Dict, Any, Tuple\n\nimport torch\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Optimizer\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nimport timm\nfrom torchvision import transforms\n\n# ──────────────────────────────────────────────────────────────────────────\n# 0. Config & Globals\n# -------------------------------------------------------------------------\n\nCFG: Dict[str, Any] = {\n    \"EPOCHS\": 20,\n    \"PATIENCE\": 5,\n    \"T_0\": 10,\n    \"BATCH_SIZE\": 16,\n    \"NUM_WORKERS\": 4,\n    \"IMG_SIZE\": 480,\n    \"VAL_RATIO\": 0.1,\n}\n\nDATA_DIR = Path(\"/kaggle/input/car-classfication\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\nSAVE_DIR = Path(\"/kaggle/working\")\nSAVE_DIR.mkdir(parents=True, exist_ok=True)\n\nBEST_MODEL_PATH = SAVE_DIR / \"best_model.pth\"\nCKPT_PATH = SAVE_DIR / \"last_checkpoint.pth\"\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Read class names\nCLASS_NAMES = sorted([p.name for p in TRAIN_DIR.iterdir() if p.is_dir()])\nNUM_CLASSES = len(CLASS_NAMES)\nLABEL_TO_IDX = {label: idx for idx, label in enumerate(CLASS_NAMES)}\n\n# ──────────────────────────────────────────────────────────────────────────\n# 1. Utility: EarlyStopping (accuracy based)\n# -------------------------------------------------------------------------\n\nclass EarlyStopping:\n    def __init__(self, patience: int, path: str | os.PathLike):\n        self.patience = patience\n        self.counter = 0\n        self.best_score = -float(\"inf\")\n        self.early_stop = False\n        self.path = Path(path)\n\n    def __call__(self, score: float, model: nn.Module):\n        if score > self.best_score:\n            self.best_score = score\n            self.counter = 0\n            state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n            torch.save(state_dict, self.path)\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n\n# ──────────────────────────────────────────────────────────────────────────\n# 2. Dataset & Transforms\n# -------------------------------------------------------------------------\n\ndef pad_to_square(img: Image.Image, fill_color=(0, 0, 0)):\n    w, h = img.size\n    max_side = max(w, h)\n    pad_w = (max_side - w) // 2\n    pad_h = (max_side - h) // 2\n    padding = (pad_w, pad_h, max_side - w - pad_w, max_side - h - pad_h)\n    return transforms.functional.pad(img, padding, fill=fill_color, padding_mode='constant')\n\ntrain_tf = transforms.Compose([\n    transforms.Lambda(pad_to_square),          # 정사각 패딩\n\n    # ── 전신 그대로(Resize) ↔ 랜덤 크롭(RandomResizedCrop) 1:1 ──\n    transforms.RandomChoice([\n        transforms.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n        transforms.RandomResizedCrop(\n            CFG[\"IMG_SIZE\"],\n            scale=(0.90, 1.0),      # 90~100 % 면적\n            ratio=(0.95, 1.05)      # 가로·세로 비율 변화 최소\n        )\n    ]),\n\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(15),\n\n    # 50 % 확률로 밝기·채도·대비·Hue 변형\n    transforms.RandomApply(\n        [transforms.ColorJitter(0.2, 0.2, 0.2, 0.05)], p=0.5\n    ),\n\n    # 30 % 확률로 원근(Perspective) 변형\n    transforms.RandomPerspective(distortion_scale=0.08, p=0.3),\n\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225]),\n\n    # 40 % 확률로 RandomErasing\n    transforms.RandomErasing(scale=(0.02, 0.1),\n                             ratio=(0.3, 3.3), p=0.4)\n])\n\n\ntest_tf = transforms.Compose([\n    transforms.Lambda(lambda img: pad_to_square(img)),\n    transforms.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nclass CustomDataset(Dataset):\n    def __init__(self, samples, transform=None):\n        self.samples = samples\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label = self.samples[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\nclass TestDataset(Dataset):\n    def __init__(self, paths, transform=None):\n        self.paths = paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img\n\n# ──────────────────────────────────────────────────────────────────────────\n# 3. Build model / loaders\n# -------------------------------------------------------------------------\n\ndef build_model() -> nn.Module:\n    model = timm.create_model(\"efficientnetv2_rw_m\", pretrained=True, num_classes=NUM_CLASSES)\n    return model\n\ndef build_loaders() -> Tuple[DataLoader, DataLoader, DataLoader, list[Path]]:\n    train_samples = []\n    for class_dir in TRAIN_DIR.iterdir():\n        if class_dir.is_dir():\n            label = LABEL_TO_IDX[class_dir.name]\n            for img_path in class_dir.glob(\"*.jpg\"):\n                train_samples.append((img_path, label))\n\n    train_imgs, val_imgs = train_test_split(train_samples, test_size=CFG[\"VAL_RATIO\"], stratify=[label for _, label in train_samples], random_state=42)\n\n    train_ds = CustomDataset(train_imgs, transform=train_tf)\n    val_ds = CustomDataset(val_imgs, transform=test_tf)\n\n    train_loader = DataLoader(train_ds, batch_size=CFG[\"BATCH_SIZE\"], shuffle=True,\n                              num_workers=CFG[\"NUM_WORKERS\"], pin_memory=True, persistent_workers=True, drop_last=True)\n    val_loader = DataLoader(val_ds, batch_size=CFG[\"BATCH_SIZE\"], shuffle=False,\n                            num_workers=CFG[\"NUM_WORKERS\"], pin_memory=True, persistent_workers=True)\n\n    test_paths = sorted(list(TEST_DIR.glob(\"*.jpg\")))\n    test_ds = TestDataset(test_paths, transform=test_tf)\n    test_loader = DataLoader(test_ds, batch_size=CFG[\"BATCH_SIZE\"], shuffle=False,\n                             num_workers=CFG[\"NUM_WORKERS\"], pin_memory=True, persistent_workers=True)\n\n    return train_loader, val_loader, test_loader, test_paths\n\n# ──────────────────────────────────────────────────────────────────────────\n# 4. Optimizer & Scheduler\n# -------------------------------------------------------------------------\n\ndef build_optim_sched(model: nn.Module) -> Tuple[Optimizer, CosineAnnealingWarmRestarts]:\n    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG[\"T_0\"], T_mult=1)\n    return optimizer, scheduler\n\n# ──────────────────────────────────────────────────────────────────────────\n# 5. Checkpoint\n# -------------------------------------------------------------------------\n\ndef load_checkpoint_if_exists(model: nn.Module, optimizer: Optimizer, scaler: GradScaler,\n                              scheduler: CosineAnnealingWarmRestarts) -> int:\n    start_epoch = 0\n    if CKPT_PATH.exists():\n        print(f\"✅ Checkpoint found. Loading from {CKPT_PATH}\")\n        ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n        model.load_state_dict(ckpt[\"model_state\"])\n        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n        scaler.load_state_dict(ckpt[\"scaler_state\"])\n        scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n        start_epoch = ckpt[\"epoch\"] + 1\n        print(f\"➡️  Resuming from epoch {start_epoch}\")\n    return start_epoch\n\n# ──────────────────────────────────────────────────────────────────────────\n# 6. Train & Validate\n# -------------------------------------------------------------------------\n\ndef train_one_epoch(model, loader, optimizer, scaler, scheduler, epoch):\n    model.train()\n    running_loss = 0.0\n    pbar = tqdm(loader, desc=f\"Epoch {epoch}\", ncols=110, leave=False)\n    for step, (xb, yb) in enumerate(pbar):\n        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n\n        with autocast(dtype=torch.float16):\n            preds = model(xb)\n            loss = criterion(preds, yb)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step(epoch + (step + 1) / len(loader))\n\n        running_loss += loss.item()\n        pbar.set_postfix(loss=f\"{running_loss / (step + 1):.4f}\")\n\n    return running_loss / len(loader)\n\ndef validate(model, loader):\n    model.eval()\n    val_loss, correct, total = 0.0, 0, 0\n    with torch.no_grad():\n        for xb, yb in loader:\n            xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n            with autocast(dtype=torch.float16):\n                preds = model(xb)\n                loss = criterion(preds, yb)\n            val_loss += loss.item()\n            correct += (preds.argmax(1) == yb).sum().item()\n            total += yb.size(0)\n    return val_loss / len(loader), correct / total\n\n# ──────────────────────────────────────────────────────────────────────────\n# 7. Main train\n# -------------------------------------------------------------------------\n\ndef fit():\n    train_loader, val_loader, test_loader, test_paths = build_loaders()\n\n    model = build_model()\n    if torch.cuda.device_count() > 1:\n        model = nn.DataParallel(model)\n    model.to(DEVICE)\n\n    optimizer, scheduler = build_optim_sched(model)\n    scaler = GradScaler(enabled=DEVICE.type == \"cuda\")\n    start_epoch = load_checkpoint_if_exists(model, optimizer, scaler, scheduler)\n\n    early_stopping = EarlyStopping(patience=CFG[\"PATIENCE\"], path=BEST_MODEL_PATH)\n\n    global criterion\n    criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\n    for epoch in range(start_epoch, CFG[\"EPOCHS\"]):\n        train_loss = train_one_epoch(model, train_loader, optimizer, scaler, scheduler, epoch)\n        val_loss, val_acc = validate(model, val_loader)\n        print(f\"Epoch {epoch:02d} | Train {train_loss:.4f} | Val {val_loss:.4f} | Acc {val_acc:.4f}\")\n\n        ckpt = {\n            \"epoch\": epoch,\n            \"model_state\": model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n            \"scaler_state\": scaler.state_dict(),\n            \"scheduler_state\": scheduler.state_dict(),\n        }\n        torch.save(ckpt, CKPT_PATH)\n\n        early_stopping(val_acc, model)\n        if early_stopping.early_stop:\n            print(\"\\n🚨 Early stopping triggered\")\n            break\n\n    best_state = torch.load(BEST_MODEL_PATH, map_location=DEVICE)\n    model.load_state_dict(best_state)\n    return model, test_loader, test_paths\n\n# ──────────────────────────────────────────────────────────────────────────\n# 8. Inference\n# -------------------------------------------------------------------------\n\ndef inference(model, test_loader, test_paths):\n    model.eval()\n    all_probs = []\n    with torch.inference_mode():\n        for xb in tqdm(test_loader, desc=\"Test\", ncols=100, leave=False):\n            xb = xb.to(DEVICE, non_blocking=True)\n            with autocast(dtype=torch.float16):\n                preds = model(xb)\n            probs = preds.softmax(dim=1).cpu().numpy()\n            all_probs.append(probs)\n    probs_cat = np.concatenate(all_probs, axis=0)\n    final_preds = probs_cat.argmax(1)\n\n    sub = pd.DataFrame({\n        \"id\": [p.stem for p in test_paths],\n        \"label\": final_preds,\n    })\n    sub.to_csv(SAVE_DIR / \"submission.csv\", index=False, encoding=\"utf-8-sig\")\n    print(f\"✅ submission.csv saved to {SAVE_DIR}\")\n\n# ──────────────────────────────────────────────────────────────────────────\n# 9. Entry point\n# -------------------------------------------------------------------------\n\nif __name__ == \"__main__\":\n    model, test_loader, test_paths = fit()\n    inference(model, test_loader, test_paths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:46:12.87674Z","iopub.execute_input":"2025-06-04T06:46:12.87702Z","iopub.status.idle":"2025-06-04T06:46:46.891806Z","shell.execute_reply.started":"2025-06-04T06:46:12.877001Z","shell.execute_reply":"2025-06-04T06:46:46.890711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport gc\n\ntorch.cuda.empty_cache()  # GPU 메모리 비우기\ngc.collect()  # 가비지 컬렉션 실행","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T07:19:25.131391Z","iopub.execute_input":"2025-06-04T07:19:25.131716Z","iopub.status.idle":"2025-06-04T07:19:25.458363Z","shell.execute_reply.started":"2025-06-04T07:19:25.131695Z","shell.execute_reply":"2025-06-04T07:19:25.457634Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #──────────────────────────────────────────────\n# # 0. 라이브러리\n# #──────────────────────────────────────────────\n# from pathlib import Path\n# import random, torch\n# from PIL import Image\n# import matplotlib.pyplot as plt\n# from torchvision import transforms\n# from torchvision.transforms.functional import to_pil_image\n\n# #──────────────────────────────────────────────\n# # 1. Transform 정의 (학습 파이프라인과 동일하되 Normalize 생략)\n# #──────────────────────────────────────────────\n# IMG_SIZE = 480\n\n# def pad_to_square(img, fill_color=(0, 0, 0)):\n#     w, h = img.size\n#     max_side = max(w, h)\n#     pad_w = (max_side - w) // 2\n#     pad_h = (max_side - h) // 2\n#     padding = (pad_w, pad_h,\n#                max_side - w - pad_w,\n#                max_side - h - pad_h)\n#     return transforms.functional.pad(\n#         img, padding, fill=fill_color, padding_mode=\"constant\")\n\n# viz_tf = transforms.Compose([\n#     transforms.Lambda(pad_to_square),\n\n#     # (전신 그대로) : (90~100 % 랜덤 크롭) = 1 : 1\n#     transforms.RandomChoice([\n#         transforms.Resize((IMG_SIZE, IMG_SIZE)),\n#         transforms.RandomResizedCrop(\n#             IMG_SIZE, scale=(0.9, 1.0))\n#     ]),\n\n#     transforms.RandomHorizontalFlip(p=0.5),\n#     transforms.RandomRotation(15),\n\n#     # 50 % 확률로만 색·명도 변형\n#     transforms.RandomApply(\n#         [transforms.ColorJitter(0.2, 0.2, 0.2, 0.05)], p=0.5),\n\n#     # 30 % 확률로 원근 변형\n#     transforms.RandomPerspective(0.08, p=0.3),\n\n#     transforms.ToTensor()            # ※ Normalize 없음 (시각화용)\n# ])\n\n# #──────────────────────────────────────────────\n# # 2. 시각화 함수\n# #──────────────────────────────────────────────\n# def show_augmented_samples(img_path, n=10, cols=5, seed=None):\n#     \"\"\"\n#     img_path : 시각화할 원본 이미지 경로\n#     n        : 생성할 증강 샘플 수\n#     cols     : 그리드 열 수\n#     seed     : 난수 시드 (None이면 매번 무작위)\n#     \"\"\"\n#     if seed is not None:\n#         random.seed(seed); torch.manual_seed(seed)\n\n#     img = Image.open(img_path).convert(\"RGB\")\n#     samples = [viz_tf(img) for _ in range(n)]\n\n#     rows = (n + cols - 1) // cols\n#     plt.figure(figsize=(cols * 3, rows * 3))\n#     for i, tensor in enumerate(samples, 1):\n#         plt.subplot(rows, cols, i)\n#         plt.axis(\"off\")\n#         plt.imshow(to_pil_image(tensor))\n#     plt.suptitle(img_path.name)\n#     plt.tight_layout()\n#     plt.show()\n\n# #──────────────────────────────────────────────\n# # 3. 경로 설정 & 실행\n# #──────────────────────────────────────────────\n# DIR_PATH = Path(\"/kaggle/input/car-classfication/train/1시리즈_F40_2020_2024\")\n# img_paths = sorted(list(DIR_PATH.glob(\"*.jpg\")))\n\n# sample_paths = random.sample(img_paths, k=min(3, len(img_paths)))\n\n# for p in sample_paths:\n#     print(\"▶\", p)            # 확인용 경로 출력\n#     show_augmented_samples(p, n=10, cols=5)  # ← 필요하면 n·cols 조정\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T07:16:36.102682Z","iopub.execute_input":"2025-06-04T07:16:36.103556Z","iopub.status.idle":"2025-06-04T07:16:39.330877Z","shell.execute_reply.started":"2025-06-04T07:16:36.103528Z","shell.execute_reply":"2025-06-04T07:16:39.330143Z"}},"outputs":[],"execution_count":null}]}