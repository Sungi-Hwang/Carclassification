{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11996333,"sourceType":"datasetVersion","datasetId":7545953}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-06-04T05:46:41.643369Z","iopub.execute_input":"2025-06-04T05:46:41.643655Z"}}},{"cell_type":"code","source":"# Swin‑Tiny 기반 차량 분류 파이프라인 (Kaggle)\n# --------------------------------------------------\n# - ConvNeXt‑Tiny, B5 와 앙상블 시 정보 다양성을 극대화하기 위해 Transformer 계열(Swin‑Tiny)을 채택\n# - 30 K 데이터셋에서도 안정적으로 학습할 수 있도록 RandAugment+MixUp/CutMix 를 포함\n# --------------------------------------------------\n\nfrom __future__ import annotations\n\nimport os\nfrom pathlib import Path\nfrom typing import Dict, Any, Tuple, List\n\nimport torch\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import Optimizer\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nimport timm\nfrom timm.data import Mixup, RandAugment\nfrom timm.loss import SoftTargetCrossEntropy\nfrom torchvision import transforms\n\n# ──────────────────────────────────────────────────────────────────────────\n# 0. Config & Globals\n# -------------------------------------------------------------------------\n\nCFG: Dict[str, Any] = {\n    \"MODEL\": \"swin_tiny_patch4_window7_224\",  # Swin‑Tiny (patch 4, win 7, 224×224)\n    \"EPOCHS\": 20,\n    \"PATIENCE\": 5,\n    \"T_0\": 10,\n    \"BATCH_SIZE\": 32,            # 16 GB GPU 기준 224² 배치 32 OK ‑ 부족하면 16 으로 ↓\n    \"NUM_WORKERS\": 4,\n    \"IMG_SIZE\": 224,             # 학습 후반(혹은 2nd stage)에 384 로 키우면 +1~2 pp\n    \"VAL_RATIO\": 0.1,\n    \"MIXUP_PROB\": 0.8,\n    \"MIXUP_ALPHA\": 0.2,\n    \"CUTMIX_ALPHA\": 1.0,\n}\n\nDATA_DIR = Path(\"/kaggle/input/car-classfication\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\nSAVE_DIR = Path(\"/kaggle/working\")\nSAVE_DIR.mkdir(parents=True, exist_ok=True)\n\nBEST_MODEL_PATH = SAVE_DIR / \"best_model_swin.pth\"\nCKPT_PATH = SAVE_DIR / \"ckpt_swin.pth\"\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Read class names\nCLASS_NAMES = sorted([p.name for p in TRAIN_DIR.iterdir() if p.is_dir()])\nNUM_CLASSES = len(CLASS_NAMES)\nLABEL_TO_IDX = {label: idx for idx, label in enumerate(CLASS_NAMES)}\n\n# ──────────────────────────────────────────────────────────────────────────\n# 1. Utility: EarlyStopping (accuracy based)\n# -------------------------------------------------------------------------\n\n\nclass EarlyStopping:\n    def __init__(self, patience: int, path: str | os.PathLike):\n        self.patience = patience\n        self.counter = 0\n        self.best_score = -float(\"inf\")\n        self.early_stop = False\n        self.path = Path(path)\n\n    def __call__(self, score: float, model: nn.Module):\n        if score > self.best_score:\n            self.best_score = score\n            self.counter = 0\n            state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n            torch.save(state_dict, self.path)\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 2. Dataset & Transforms\n# -------------------------------------------------------------------------\n\n\ndef pad_to_square(img: Image.Image, fill_color=(0, 0, 0)):\n    w, h = img.size\n    max_side = max(w, h)\n    pad_w = (max_side - w) // 2\n    pad_h = (max_side - h) // 2\n    padding = (pad_w, pad_h, max_side - w - pad_w, max_side - h - pad_h)\n    return transforms.functional.pad(img, padding, fill=fill_color, padding_mode=\"constant\")\n\n\nrand_augment = RandAugment(num_layers=2, magnitude=9)\n\ntrain_tf = transforms.Compose([\n    transforms.Lambda(pad_to_square),\n    transforms.RandomChoice([\n        transforms.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n        transforms.RandomResizedCrop(CFG[\"IMG_SIZE\"], scale=(0.7, 1.0), ratio=(0.9, 1.1)),\n    ]),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    rand_augment,\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n    transforms.RandomErasing(p=0.25, scale=(0.02, 0.1), ratio=(0.3, 3.3), value=\"random\"),\n])\n\n\nval_tf = transforms.Compose([\n    transforms.Lambda(pad_to_square),\n    transforms.Resize((CFG[\"IMG_SIZE\"], CFG[\"IMG_SIZE\"])),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\n\n\nclass CustomDataset(Dataset):\n    def __init__(self, samples: List[Tuple[Path, int]], transform=None):\n        self.samples = samples\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx: int):\n        img_path, label = self.samples[idx]\n        img = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img, label\n\n\nclass TestDataset(Dataset):\n    def __init__(self, paths: List[Path], transform=None):\n        self.paths = paths\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx: int):\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        return img\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 3. Build model / loaders\n# -------------------------------------------------------------------------\n\n\ndef build_model() -> nn.Module:\n    model = timm.create_model(CFG[\"MODEL\"], pretrained=True, num_classes=NUM_CLASSES)\n    return model\n\n\ndef build_loaders() -> Tuple[DataLoader, DataLoader, DataLoader, List[Path]]:\n    train_samples = []\n    for class_dir in TRAIN_DIR.iterdir():\n        if class_dir.is_dir():\n            label = LABEL_TO_IDX[class_dir.name]\n            for img_path in class_dir.glob(\"*.jpg\"):\n                train_samples.append((img_path, label))\n\n    train_imgs, val_imgs = train_test_split(\n        train_samples,\n        test_size=CFG[\"VAL_RATIO\"],\n        stratify=[label for _, label in train_samples],\n        random_state=42,\n    )\n\n    train_ds = CustomDataset(train_imgs, transform=train_tf)\n    val_ds = CustomDataset(val_imgs, transform=val_tf)\n\n    train_loader = DataLoader(\n        train_ds,\n        batch_size=CFG[\"BATCH_SIZE\"],\n        shuffle=True,\n        num_workers=CFG[\"NUM_WORKERS\"],\n        pin_memory=True,\n        persistent_workers=True,\n        drop_last=True,\n    )\n    val_loader = DataLoader(\n        val_ds,\n        batch_size=CFG[\"BATCH_SIZE\"],\n        shuffle=False,\n        num_workers=CFG[\"NUM_WORKERS\"],\n        pin_memory=True,\n        persistent_workers=True,\n    )\n\n    test_paths = sorted(list(TEST_DIR.glob(\"*.jpg\")))\n    test_ds = TestDataset(test_paths, transform=val_tf)\n    test_loader = DataLoader(\n        test_ds,\n        batch_size=CFG[\"BATCH_SIZE\"],\n        shuffle=False,\n        num_workers=CFG[\"NUM_WORKERS\"],\n        pin_memory=True,\n        persistent_workers=True,\n    )\n\n    return train_loader, val_loader, test_loader, test_paths\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 4. Optimizer & Scheduler\n# -------------------------------------------------------------------------\n\n\ndef build_optim_sched(model: nn.Module) -> Tuple[Optimizer, CosineAnnealingWarmRestarts]:\n    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=5e-2)\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG[\"T_0\"], T_mult=1)\n    return optimizer, scheduler\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 5. Checkpoint\n# -------------------------------------------------------------------------\n\n\ndef load_checkpoint_if_exists(\n    model: nn.Module,\n    optimizer: Optimizer,\n    scaler: GradScaler,\n    scheduler: CosineAnnealingWarmRestarts,\n) -> int:\n    start_epoch = 0\n    if CKPT_PATH.exists():\n        print(f\"✅ Checkpoint found. Loading from {CKPT_PATH}\")\n        ckpt = torch.load(CKPT_PATH, map_location=DEVICE)\n        model.load_state_dict(ckpt[\"model_state\"])\n        optimizer.load_state_dict(ckpt[\"optimizer_state\"])\n        scaler.load_state_dict(ckpt[\"scaler_state\"])\n        scheduler.load_state_dict(ckpt[\"scheduler_state\"])\n        start_epoch = ckpt[\"epoch\"] + 1\n        print(f\"➡️  Resuming from epoch {start_epoch}\")\n    return start_epoch\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 6. Train & Validate\n# -------------------------------------------------------------------------\n\n\ndef train_one_epoch(model, loader, optimizer, scaler, scheduler, epoch, mixup_fn):\n    model.train()\n    running_loss = 0.0\n    pbar = tqdm(loader, desc=f\"Epoch {epoch}\", ncols=110, leave=False)\n    for step, (xb, yb) in enumerate(pbar):\n        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n\n        # MixUp / CutMix\n        if mixup_fn is not None:\n            xb, yb = mixup_fn(xb, yb)\n\n        with autocast(dtype=torch.float16):\n            preds = model(xb)\n            loss = criterion(preds, yb)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step(epoch + (step + 1) / len(loader))\n\n        running_loss += loss.item()\n        pbar.set_postfix(loss=f\"{running_loss / (step + 1):.4f}\")\n\n    return running_loss / len(loader)\n\n\n@torch.no_grad()\ndef validate(model, loader):\n    model.eval()\n    val_loss, correct, total = 0.0, 0, 0\n    for xb, yb in loader:\n        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n        with autocast(dtype=torch.float16):\n            preds = model(xb)\n            loss = criterion_val(preds, yb)\n        val_loss += loss.item()\n        correct += (preds.argmax(1) == yb).sum().item()\n        total += yb.size(0)\n    return val_loss / len(loader), correct / total\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 7. Main train\n# -------------------------------------------------------------------------\n\n\ndef fit():\n    train_loader, val_loader, test_loader, test_paths = build_loaders()\n\n    model = build_model()\n    if torch.cuda.device_count() > 1:\n        model = nn.DataParallel(model)\n    model.to(DEVICE)\n\n    optimizer, scheduler = build_optim_sched(model)\n    scaler = GradScaler(enabled=DEVICE.type == \"cuda\")\n    start_epoch = load_checkpoint_if_exists(model, optimizer, scaler, scheduler)\n\n    mixup_fn = Mixup(\n        mixup_alpha=CFG[\"MIXUP_ALPHA\"],\n        cutmix_alpha=CFG[\"CUTMIX_ALPHA\"],\n        prob=CFG[\"MIXUP_PROB\"],\n        num_classes=NUM_CLASSES,\n        label_smoothing=0.1,\n    )\n\n    early_stopping = EarlyStopping(patience=CFG[\"PATIENCE\"], path=BEST_MODEL_PATH)\n\n    for epoch in range(start_epoch, CFG[\"EPOCHS\"]):\n        train_loss = train_one_epoch(model, train_loader, optimizer, scaler, scheduler, epoch, mixup_fn)\n        val_loss, val_acc = validate(model, val_loader)\n        print(f\"Epoch {epoch:02d} | Train {train_loss:.4f} | Val {val_loss:.4f} | Acc {val_acc:.4f}\")\n\n        ckpt = {\n            \"epoch\": epoch,\n            \"model_state\": model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n            \"scaler_state\": scaler.state_dict(),\n            \"scheduler_state\": scheduler.state_dict(),\n        }\n        torch.save(ckpt, CKPT_PATH)\n\n        early_stopping(val_acc, model)\n        if early_stopping.early_stop:\n            print(\"\\n🚨 Early stopping triggered\")\n            break\n\n    best_state = torch.load(BEST_MODEL_PATH, map_location=DEVICE)\n    model.load_state_dict(best_state)\n    return model, test_loader, test_paths\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 8. Inference\n# -------------------------------------------------------------------------\n\n\ndef inference(model, test_loader, test_paths):\n    model.eval()\n    all_probs = []\n    with torch.inference_mode():\n        for xb in tqdm(test_loader, desc=\"Test\", ncols=100, leave=False):\n            xb = xb.to(DEVICE, non_blocking=True)\n            with autocast(dtype=torch.float16):\n                preds = model(xb)\n            probs = preds.softmax(dim=1).cpu().numpy()\n            all_probs.append(probs)\n    probs_cat = np.concatenate(all_probs, axis=0)\n    final_preds = probs_cat.argmax(1)\n\n    sub = pd.DataFrame({\n        \"id\": [p.stem for p in test_paths],\n        \"label\": final_preds,\n    })\n    sub.to_csv(SAVE_DIR / \"submission_swin.csv\", index=False, encoding=\"utf-8-sig\")\n    print(f\"✅ submission_swin.csv saved to {SAVE_DIR}\")\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 9. Loss (defined globally to share across funcs)\n# -------------------------------------------------------------------------\n\ncriterion = SoftTargetCrossEntropy()\ncriterion_val = nn.CrossEntropyLoss()\n\n\n# ──────────────────────────────────────────────────────────────────────────\n# 10. Entry point\n# -------------------------------------------------------------------------\n\nif __name__ == \"__main__\":\n    model, test_loader, test_paths = fit()\n    inference(model, test_loader, test_paths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:36:38.764402Z","iopub.execute_input":"2025-06-04T06:36:38.764662Z","iopub.status.idle":"2025-06-04T06:36:38.844846Z","shell.execute_reply.started":"2025-06-04T06:36:38.764644Z","shell.execute_reply":"2025-06-04T06:36:38.843828Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Swin‑Tiny 전체 파이프라인 — EMA · LLRD · Gradual‑Resize · MixUp/CutMix · Weighted Sampler · Grad‑Accum\n# =========================================================================================\n# Transformer 모델 1종을 CNN 두 모델(B5, ConvNeXt‑Tiny)과 앙상블할 때 최대한 정보 다양성을 확보하기 위한 풀옵션 레시피\n# -----------------------------------------------------------------------------------------\n\nfrom __future__ import annotations\n\nimport os, math, collections\nfrom pathlib import Path\nfrom typing import Dict, Any, Tuple, List\n\nimport torch\nfrom torch import nn\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nimport timm\nfrom timm.data import Mixup, RandAugment\nfrom timm.loss import SoftTargetCrossEntropy\nfrom timm.layers import set_grad_layer_decay\nfrom timm.utils import ModelEma\nfrom torchvision import transforms\n\n# ───────────────────────── 0. Config & Paths ─────────────────────────\nCFG: Dict[str, Any] = {\n    \"MODEL\": \"swin_tiny_patch4_window7_224\",\n    \"STAGES\": [(224, 10), (320, 5), (384, 5)],\n    \"BASE_LR\": 5e-4,\n    \"LAYER_DECAY\": 0.7,\n    \"EMA_DECAY\": 0.9999,\n    \"BATCH_SIZE\": 32,\n    \"TARGET_BATCH\": 256,\n    \"NUM_WORKERS\": 4,\n    \"PATIENCE\": 5,\n    \"T_0\": 10,\n    \"VAL_RATIO\": 0.1,\n    \"MIXUP_ALPHA\": 0.2,\n    \"CUTMIX_ALPHA\": 1.0,\n    \"MIXUP_PROB\": 0.8,\n}\n\nDATA_DIR = Path(\"/kaggle/input/car-classfication\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR  = DATA_DIR / \"test\"\nSAVE_DIR  = Path(\"/kaggle/working\"); SAVE_DIR.mkdir(parents=True, exist_ok=True)\nBEST_MODEL_PATH = SAVE_DIR / \"best_model_swin.pth\"\nCKPT_PATH       = SAVE_DIR / \"ckpt_swin.pth\"\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nCLASS_NAMES = sorted([p.name for p in TRAIN_DIR.iterdir() if p.is_dir()])\nNUM_CLASSES = len(CLASS_NAMES)\nLABEL_TO_IDX = {c:i for i,c in enumerate(CLASS_NAMES)}\n\n# ───────────────────────── 1. Utils ─────────────────────────\nclass EarlyStopping:\n    def __init__(self, patience:int, path:Path):\n        self.patience, self.path = patience, path\n        self.counter, self.best = 0, -float(\"inf\")\n        self.early_stop=False\n    def __call__(self, score:float, model:nn.Module):\n        if score>self.best:\n            self.best, self.counter = score, 0\n            torch.save(model.state_dict(), self.path)\n        else:\n            self.counter +=1\n            if self.counter>=self.patience: self.early_stop=True\n\n_pad = lambda img: transforms.functional.pad(img,\n    ((max(img.size)-img.size[0])//2,\n     (max(img.size)-img.size[1])//2,\n     (max(img.size)-img.size[0]+1)//2,\n     (max(img.size)-img.size[1]+1)//2), fill=(0,0,0))\n# rand_aug = RandAugment(num_layers=2, magnitude=9)\n\ndef tf_comp(size: int, train: bool):\n    base = [transforms.Lambda(_pad)]  # 긴 변 기준 패딩\n    if train:\n        base += [\n            transforms.RandomResizedCrop(\n                size,\n                scale=(0.8, 1.0),   # 덜 aggressive하게\n                ratio=(0.9, 1.1)\n            ),\n            transforms.RandomHorizontalFlip(),  # 좌우 반전\n        ]\n    else:\n        base += [\n            transforms.Resize((size, size))  # validation/test는 그냥 Resize\n        ]\n    base += [\n        transforms.ToTensor(),\n        transforms.Normalize(\n            mean=[0.485, 0.456, 0.406],\n            std=[0.229, 0.224, 0.225]\n        )  # ImageNet Normalization\n    ]\n    return transforms.Compose(base)\n\n\nclass ClsDS(Dataset):\n    def __init__(self, items, tf): self.items, self.tf = items, tf\n    def __len__(self): return len(self.items)\n    def __getitem__(self, idx): p,l=self.items[idx]; return self.tf(Image.open(p).convert(\"RGB\")), l\nclass ImgDS(Dataset):\n    def __init__(self, paths, tf): self.paths, self.tf = paths, tf\n    def __len__(self): return len(self.paths)\n    def __getitem__(self, idx): return self.tf(Image.open(self.paths[idx]).convert(\"RGB\"))\n\n# ───────────────────────── 2. Data & Model ─────────────────────────\n\ndef loaders(size:int):\n    items=[(p, LABEL_TO_IDX[p.parent.name]) for p in TRAIN_DIR.rglob(\"*.jpg\")]\n    tr,va=train_test_split(items,test_size=CFG[\"VAL_RATIO\"],stratify=[l for _,l in items],random_state=42)\n    cnt=collections.Counter(l for _,l in tr); w=[1/cnt[l] for _,l in tr]\n    sampler=WeightedRandomSampler(w,len(tr),replacement=True)\n    tr_ld=DataLoader(ClsDS(tr,tf_comp(size,True)),batch_size=CFG[\"BATCH_SIZE\"],sampler=sampler,num_workers=CFG[\"NUM_WORKERS\"],pin_memory=True,persistent_workers=True)\n    va_ld=DataLoader(ClsDS(va,tf_comp(size,False)),batch_size=CFG[\"BATCH_SIZE\"],shuffle=False,num_workers=CFG[\"NUM_WORKERS\"],pin_memory=True,persistent_workers=True)\n    t_paths=sorted(TEST_DIR.glob(\"*.jpg\"))\n    ts_ld=DataLoader(ImgDS(t_paths,tf_comp(size,False)),batch_size=CFG[\"BATCH_SIZE\"],shuffle=False,num_workers=CFG[\"NUM_WORKERS\"],pin_memory=True,persistent_workers=True)\n    return tr_ld,va_ld,ts_ld,t_paths\n\ndef build_model():\n    return timm.create_model(CFG[\"MODEL\"],pretrained=True,num_classes=NUM_CLASSES)\n\ndef param_groups(model):\n    set_grad_layer_decay(model,decay_rate=CFG[\"LAYER_DECAY\"],param_group_fn=None)\n    groups=[]\n    for n,p in model.named_parameters():\n        if not p.requires_grad: continue\n        lid=p.layer_id if hasattr(p,'layer_id') else 0\n        groups.append({\"params\":[p],\"lr\":CFG[\"BASE_LR\"]*(CFG[\"LAYER_DECAY\"]**lid),\"weight_decay\":0.05 if p.ndim>1 else 0.0})\n    return groups\n\n# ───────────────────────── 3. Train / Val helpers ─────────────────────────\ncrit_tr=SoftTargetCrossEntropy(); crit_va=nn.CrossEntropyLoss()\n\ndef epoch_run(model,loader,opt,scaler,sched,mix,ema,acc,train=True):\n    model.train() if train else model.eval()\n    tot,correct,tloss=0,0,0.0\n    if train: opt.zero_grad(set_to_none=True)\n    pbar=tqdm(loader,leave=False,ncols=110,desc=\"Train\" if train else \"Val\")\n    for i,(xb,yb) in enumerate(pbar):\n        xb,yb=xb.to(DEVICE,non_blocking=True), yb.to(DEVICE,non_blocking=True)\n        if train and mix: xb,yb=mix(xb,yb)\n        with autocast(dtype=torch.float16): pr=model(xb); loss=(crit_tr if train else crit_va)(pr,yb)\n        if train:\n            loss=loss/acc; scaler.scale(loss).backward()\n            if (i+1)%acc==0:\n                scaler.step(opt); scaler.update(); opt.zero_grad(set_to_none=True); sched.step()\n                if ema: ema.update(model)\n        tloss+=loss.item()*xb.size(0)*acc if train else loss.item()*xb.size(0)\n        if not train:\n            correct+=(pr.argmax(1)==yb).sum().item(); tot+=yb.size(0)\n        pbar.set_postfix(loss=f\"{tloss/len(loader.dataset):.4f}\")\n    return (tloss/len(loader.dataset)) if train else (tloss/len(loader.dataset),correct/tot)\n\n\n# ───────────────────────── 4. Fit & Inference ─────────────────────────\n\ndef fit():\n    model = build_model().to(DEVICE)\n    if torch.cuda.device_count() > 1:\n        model = nn.DataParallel(model)\n\n    ema     = ModelEma(model, decay=CFG[\"EMA_DECAY\"])          # EMA shadow\n    optimizer = torch.optim.AdamW(param_groups(model), betas=(0.9, 0.999))\n    scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG[\"T_0\"], T_mult=1)\n    scaler   = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n\n    accum_steps = math.ceil(CFG[\"TARGET_BATCH\"] / CFG[\"BATCH_SIZE\"])\n    mixup_fn = Mixup(\n        num_classes   = NUM_CLASSES,\n        mixup_alpha   = CFG[\"MIXUP_ALPHA\"],\n        cutmix_alpha  = CFG[\"CUTMIX_ALPHA\"],\n        prob          = CFG[\"MIXUP_PROB\"],\n        label_smoothing = 0.1,\n        token_label   = True,\n    )\n    stopper = EarlyStopping(CFG[\"PATIENCE\"], BEST_MODEL_PATH)\n\n    # ── Multi-stage training (224 → 320 → 384) ─────────────────────────\n    for stage_idx, (img_size, epochs) in enumerate(CFG[\"STAGES\"]):\n        train_ld, val_ld, test_ld, test_paths = loaders(img_size)\n\n        for epoch in range(epochs):\n            train_loss = epoch_run(\n                model,       train_ld,\n                optimizer,   scaler,\n                scheduler,   mixup_fn,\n                ema,         accum_steps,\n                train=True\n            )\n            val_loss, val_acc = epoch_run(\n                ema.ema_module, val_ld,\n                optimizer, scaler, scheduler,\n                mixup_fn=None, ema=None,\n                acc=accum_steps, train=False\n            )\n\n            print(\n                f\"Stage{stage_idx}-{img_size}px | \"\n                f\"Ep {epoch:02d}/{epochs:02d} | \"\n                f\"Train {train_loss:.4f} | Val {val_loss:.4f} | Acc {val_acc:.4f}\"\n            )\n\n            # ── 중간 체크포인트 저장 ─────────────────────\n            torch.save(\n                {\n                    \"stage\"     : stage_idx,\n                    \"epoch\"     : epoch,\n                    \"model_state\": model.state_dict(),\n                    \"optimizer_state\": optimizer.state_dict(),\n                    \"scaler_state\"   : scaler.state_dict(),\n                    \"scheduler_state\": scheduler.state_dict(),\n                },\n                CKPT_PATH,\n            )\n\n            # ── Early-Stopping 검사 ─────────────────────\n            stopper(val_acc, ema.ema_module)\n            if stopper.early_stop:\n                print(\"🚨 Early stopping triggered\")\n                break\n\n        if stopper.early_stop:\n            break  # 밖의 stage loop도 탈출\n\n    # ── 최종 Best 가중치 로드 ───────────────────────────\n    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=DEVICE))\n    return model, test_ld, test_paths\n# ───────────────────────── 5. Inference ─────────────────────────\n@torch.no_grad()\ndef inference(model: nn.Module,\n              loader: DataLoader,\n              test_paths: List[Path],\n              tta: bool = False):\n    \"\"\"\n    tta=True → horizontal-flip 한 번만 추가해 2-view 평균\n    \"\"\"\n    model.eval()\n    all_probs = []\n    for xb in tqdm(loader, desc=\"Test\", ncols=100, leave=False):\n        xb = xb.to(DEVICE, non_blocking=True)\n\n        if tta:\n            xb_flipped = torch.flip(xb, dims=[3])\n            xb = torch.cat([xb, xb_flipped], dim=0)\n\n        with autocast(dtype=torch.float16):\n            preds = model(xb)\n            if tta:\n                preds = (preds[0::2] + preds[1::2]) / 2.0   # 2-view average\n        all_probs.append(preds.softmax(1).cpu().numpy())\n\n    probs = np.concatenate(all_probs, axis=0)\n    final_preds = probs.argmax(1)\n\n    sub = pd.DataFrame({\n        \"id\": [p.stem for p in test_paths],\n        \"label\": final_preds,\n    })\n    out_path = SAVE_DIR / \"submission_swin.csv\"\n    sub.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n    print(f\"✅ submission saved to {out_path}\")\n\n# ───────────────────────── 6. Entry point ─────────────────────────\nif __name__ == \"__main__\":\n    model, test_loader, test_paths = fit()\n    inference(model, test_loader, test_paths, tta=True)  # 필요하면 tta=False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T06:46:12.87674Z","iopub.execute_input":"2025-06-04T06:46:12.87702Z","iopub.status.idle":"2025-06-04T06:46:46.891806Z","shell.execute_reply.started":"2025-06-04T06:46:12.877001Z","shell.execute_reply":"2025-06-04T06:46:46.890711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport gc\n\ntorch.cuda.empty_cache()  # GPU 메모리 비우기\ngc.collect()  # 가비지 컬렉션 실행","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T07:19:25.131391Z","iopub.execute_input":"2025-06-04T07:19:25.131716Z","iopub.status.idle":"2025-06-04T07:19:25.458363Z","shell.execute_reply.started":"2025-06-04T07:19:25.131695Z","shell.execute_reply":"2025-06-04T07:19:25.457634Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# #──────────────────────────────────────────────\n# # 0. 라이브러리\n# #──────────────────────────────────────────────\n# from pathlib import Path\n# import random, torch\n# from PIL import Image\n# import matplotlib.pyplot as plt\n# from torchvision import transforms\n# from torchvision.transforms.functional import to_pil_image\n\n# #──────────────────────────────────────────────\n# # 1. Transform 정의 (학습 파이프라인과 동일하되 Normalize 생략)\n# #──────────────────────────────────────────────\n# IMG_SIZE = 480\n\n# def pad_to_square(img, fill_color=(0, 0, 0)):\n#     w, h = img.size\n#     max_side = max(w, h)\n#     pad_w = (max_side - w) // 2\n#     pad_h = (max_side - h) // 2\n#     padding = (pad_w, pad_h,\n#                max_side - w - pad_w,\n#                max_side - h - pad_h)\n#     return transforms.functional.pad(\n#         img, padding, fill=fill_color, padding_mode=\"constant\")\n\n# viz_tf = transforms.Compose([\n#     transforms.Lambda(pad_to_square),\n\n#     # (전신 그대로) : (90~100 % 랜덤 크롭) = 1 : 1\n#     transforms.RandomChoice([\n#         transforms.Resize((IMG_SIZE, IMG_SIZE)),\n#         transforms.RandomResizedCrop(\n#             IMG_SIZE, scale=(0.9, 1.0))\n#     ]),\n\n#     transforms.RandomHorizontalFlip(p=0.5),\n#     transforms.RandomRotation(15),\n\n#     # 50 % 확률로만 색·명도 변형\n#     transforms.RandomApply(\n#         [transforms.ColorJitter(0.2, 0.2, 0.2, 0.05)], p=0.5),\n\n#     # 30 % 확률로 원근 변형\n#     transforms.RandomPerspective(0.08, p=0.3),\n\n#     transforms.ToTensor()            # ※ Normalize 없음 (시각화용)\n# ])\n\n# #──────────────────────────────────────────────\n# # 2. 시각화 함수\n# #──────────────────────────────────────────────\n# def show_augmented_samples(img_path, n=10, cols=5, seed=None):\n#     \"\"\"\n#     img_path : 시각화할 원본 이미지 경로\n#     n        : 생성할 증강 샘플 수\n#     cols     : 그리드 열 수\n#     seed     : 난수 시드 (None이면 매번 무작위)\n#     \"\"\"\n#     if seed is not None:\n#         random.seed(seed); torch.manual_seed(seed)\n\n#     img = Image.open(img_path).convert(\"RGB\")\n#     samples = [viz_tf(img) for _ in range(n)]\n\n#     rows = (n + cols - 1) // cols\n#     plt.figure(figsize=(cols * 3, rows * 3))\n#     for i, tensor in enumerate(samples, 1):\n#         plt.subplot(rows, cols, i)\n#         plt.axis(\"off\")\n#         plt.imshow(to_pil_image(tensor))\n#     plt.suptitle(img_path.name)\n#     plt.tight_layout()\n#     plt.show()\n\n# #──────────────────────────────────────────────\n# # 3. 경로 설정 & 실행\n# #──────────────────────────────────────────────\n# DIR_PATH = Path(\"/kaggle/input/car-classfication/train/1시리즈_F40_2020_2024\")\n# img_paths = sorted(list(DIR_PATH.glob(\"*.jpg\")))\n\n# sample_paths = random.sample(img_paths, k=min(3, len(img_paths)))\n\n# for p in sample_paths:\n#     print(\"▶\", p)            # 확인용 경로 출력\n#     show_augmented_samples(p, n=10, cols=5)  # ← 필요하면 n·cols 조정\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-04T07:16:36.102682Z","iopub.execute_input":"2025-06-04T07:16:36.103556Z","iopub.status.idle":"2025-06-04T07:16:39.330877Z","shell.execute_reply.started":"2025-06-04T07:16:36.103528Z","shell.execute_reply":"2025-06-04T07:16:39.330143Z"}},"outputs":[],"execution_count":null}]}